{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Передбачення зарплат на IT-ринку України"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У цьому завданні ви працюватимете з реальними даними з [зарплатного опитування DOU.ua за травень 2016р](https://dou.ua/lenta/articles/salary-report-may-june-2016/). Ви реалізуєте зважену лінійну регресію, яка передбачає зарплати Java-інженерів, та навчите свою модель за допомогою градієнтного спуску.\n",
    "\n",
    "Заповніть пропущений код в розділі «Моделювання» (позначено коментарями) та запустіть розділ «Тестування», щоб перевірити його правильність."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext ipython_unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Підготовка даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salaries = pd.read_csv(\"data/2016_may_final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оберемо тільки Java-інженерів з-поміж усіх респондентів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_java = pd.DataFrame(df_salaries[(df_salaries[\"Язык.программирования\"] == \"Java\") &\n",
    "                                   (df_salaries[\"cls\"] == \"DEV\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейменуємо деякі колонки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_java.rename(\n",
    "    columns={\n",
    "        \"exp\": \"TotalExperience\",\n",
    "        \"loc\": \"Location\"\n",
    "    },\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закодуємо рівень англійської мови числами від 1 (найнижчий) до 5 (найвищий):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_java[\"EnglishLevel\"] = df_java[\"Уровень.английского\"].map({\n",
    "    \"элементарный\": 1,\n",
    "    \"ниже среднего\": 2,\n",
    "    \"средний\": 3,\n",
    "    \"выше среднего\": 4,\n",
    "    \"продвинутый\": 5\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закодуємо колонку Location (найбільші IT-міста або \"other\") за допомогою one-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_columns = [\n",
    "    \"LocationOther\",\n",
    "    \"LocationDnipro\",\n",
    "    \"LocationKyiv\",\n",
    "    \"LocationLviv\",\n",
    "    \"LocationOdesa\",\n",
    "    \"LocationKharkiv\"\n",
    "]\n",
    "df_java[city_columns] = pd.get_dummies(df_java[\"Location\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Відберемо такі ознаки:\n",
    "\n",
    "* Загальна кількість років досвіду\n",
    "* Рівень англійської мови\n",
    "* Місто"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\"TotalExperience\", \"EnglishLevel\"] + city_columns\n",
    "df_X = df_java[feature_columns]\n",
    "df_y = df_java[[\"salary\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X shape:\", df_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Розділимо вибірку на навчальну та тестову:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_size = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_assignment = np.random.uniform(size=len(df_X))\n",
    "\n",
    "X_train = df_X[dataset_assignment <= training_set_size].values\n",
    "y_train = df_y[dataset_assignment <= training_set_size].values.flatten()\n",
    "\n",
    "X_test = df_X[dataset_assignment > training_set_size].values\n",
    "y_test = df_y[dataset_assignment > training_set_size].values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Щоб градієнтний спуск швидше збігався, нормалізуємо навчальну вибірку так, щоб кожна ознака мала $\\mu = 0, \\sigma = 1$:\n",
    "\n",
    "$ x' = \\frac{x - \\bar{x}}{\\sigma}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_means = np.average(X_train, axis=0)\n",
    "feature_sigmas = np.std(X_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - feature_means) / feature_sigmas\n",
    "X_test = (X_test - feature_means) / feature_sigmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Додаємо уявну ознаку $x_0 = 1$ (intercept term)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not np.all(X_train[:, 0] == 1):\n",
    "    X_train = np.insert(X_train, 0, values=1, axis=1)\n",
    "    \n",
    "if not np.all(X_test[:, 0] == 1):\n",
    "    X_test = np.insert(X_test, 0, values=1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"X train: \", X_train.shape)\n",
    "print(\"y train: \", y_train.shape)\n",
    "print()\n",
    "print(\"X test:  \", X_test.shape)\n",
    "print(\"y test:  \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Моделювання"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реалізуйте функцію гіпотези лінійної регресії в матричній формі."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_linear(theta, X):\n",
    "    # =============== TODO: Your code here ===============\n",
    "    # Compute the hypothesis function for linear regression.\n",
    "    \n",
    "    return 0\n",
    "    # ===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реалізуйте функцію зважування всіх навчальних прикладів $x^{(i)}$, якщо нам дана точка передбачення $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_example_weights(X, x_pred, tau):\n",
    "    # =============== TODO: Your code here ===============\n",
    "    # Compute the weight for each example, given the\n",
    "    # prediction point (x_pred).\n",
    "    \n",
    "    weights = np.ones(X.shape[0])\n",
    "    # ====================================================\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реалізуйте функцію втрат зваженої лінійної регресії. Подумайте, як обчислити цей вираз відразу в матричному вигляді."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(theta, X, y, weights):\n",
    "    # =============== TODO: Your code here ===============\n",
    "    # Given the currently learned model weights (theta),\n",
    "    # compute the overall loss on the training set (X),\n",
    "    # taking the weights into account.\n",
    "\n",
    "    return np.random.uniform(1000)\n",
    "    # ===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реалізуйте обчислення градієнта функції втрат зваженої лінійної регресії. Подумайте, як обчислити цей вираз відразу в матричному вигляді."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function_gradient(theta, X, y, weights):\n",
    "    # =============== TODO: Your code here ===============\n",
    "    # Given the currently learned model weights (theta),\n",
    "    # compute the gradient of the cost function on the\n",
    "    # training set (X), taking the weights into account.\n",
    "\n",
    "    return np.zeros_like(theta)\n",
    "    # ===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реалізуйте один крок градієнтного спуску."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model_weights(theta, learning_rate, cost_gradient):\n",
    "    # =============== TODO: Your code here ===============\n",
    "    # Given the learning rate and the gradient of the\n",
    "    # cost function, take one gradient descent step and\n",
    "    # return the updated vector theta.\n",
    "    \n",
    "    return theta\n",
    "    # ===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Навчаємо модель:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, weights, loss_fun, grad_fun, learning_rate, convergence_threshold, max_iters, verbose=False):\n",
    "    theta = np.zeros(X.shape[1])\n",
    "    losses = []\n",
    "    \n",
    "    for i in range(max_iters):\n",
    "        loss = loss_fun(theta, X, y, weights)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Iteration: {0:3} Loss: {1}\".format(i + 1, loss))\n",
    "\n",
    "        if len(losses) > 2 and np.abs(losses[-1] - losses[-2]) <= convergence_threshold:\n",
    "            break\n",
    "        \n",
    "        grad = grad_fun(theta, X, y, weights)\n",
    "        theta = update_model_weights(theta, learning_rate, grad)\n",
    "        \n",
    "    return theta, np.array(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Передбачення нових даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_weighted_linear(X, y, x_pred, verbose=False):\n",
    "    weights = get_example_weights(X, x_pred, tau=0.1)\n",
    "    theta, losses = gradient_descent(\n",
    "        X,\n",
    "        y,\n",
    "        weights,\n",
    "        loss_fun=cost_function,\n",
    "        grad_fun=cost_function_gradient,\n",
    "        learning_rate=0.005,\n",
    "        convergence_threshold=0.0001,\n",
    "        max_iters=500,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    return predict_linear(theta, x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = X_train[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predicted = predict_weighted_linear(X_train, y_train, x_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцінимо, наскільки модель помиляється на тестовій вибірці:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.array([predict_weighted_linear(X_test, y_test, X_test[i]) for i in range(len(y_test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_residuals = pd.DataFrame(y_test - y_test_pred, columns=[\"residual\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_residuals.plot.bar(figsize=(10, 5))\n",
    "ax.legend().remove()\n",
    "ax.get_xaxis().set(ticklabels=[])\n",
    "ax.set(xlabel=\"Example #\")\n",
    "ax.set(ylabel=\"Prediction Error, $\")\n",
    "ax.set(title=\"Residuals\")\n",
    "\n",
    "bins = np.arange(-3000, 3001, 100)\n",
    "ticks = np.arange(-3000, 3001, 500)\n",
    "\n",
    "ax = df_residuals.hist(bins=bins, figsize=(10, 5))[0][0]\n",
    "ax.set(xticks=ticks)\n",
    "ax.set(xlabel=\"Prediction Error, $\")\n",
    "ax.set(ylabel=\"Frequency\")\n",
    "ax.set(title=\"Error Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестування"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустіть комірку нижче, щоб перевірити правильність вашого коду:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%unittest_main\n",
    "\n",
    "class WLRTests(unittest.TestCase):\n",
    "\n",
    "    x = np.array([1, -0.5, 3, 1])\n",
    "    X = np.array([\n",
    "        [1, -0.5, 3, 1],\n",
    "        [2, 8, -0.33, 5],\n",
    "        [0, 0, 0, 0]\n",
    "    ])\n",
    "    y = np.array([40, 100, 12])\n",
    "    theta = np.array([2, 5, 7, 9])\n",
    "    eps = 0.001\n",
    "\n",
    "    def assertFloatEquals(self, a, b):\n",
    "        self.assertTrue(np.abs(a - b) < self.eps)\n",
    "    \n",
    "    def assertArrayEquals(self, a, b):\n",
    "        a = np.array(a)\n",
    "        b = np.array(b)\n",
    "        self.assertEqual(a.shape, b.shape)\n",
    "        self.assertTrue(np.all(np.abs(a - b) < self.eps))\n",
    "    def test_predict_linear_should_compute_correct_prediction_for_1_example(self):\n",
    "        expected = 29.5\n",
    "        actual = predict_linear(self.theta, self.x)\n",
    "        self.assertEqual(actual, expected)\n",
    "    \n",
    "    def test_predict_linear_should_compute_correct_predictions_for_multiple_examples(self):\n",
    "        expected = [29.5, 86.69, 0]\n",
    "        actual = (predict_linear(self.theta, self.X))\n",
    "        self.assertArrayEquals(actual, expected)\n",
    "\n",
    "    def test_get_example_weights_should_return_properly_shaped_vector(self):\n",
    "        weights = get_example_weights(self.X, self.x, tau=5)\n",
    "        self.assertTrue(weights.shape[0] == self.X.shape[0])\n",
    "\n",
    "    def test_get_example_weights_should_compute_correct_weights(self):\n",
    "        expected = [1.000, 0.134, 0.798]\n",
    "        actual = get_example_weights(self.X, self.x, tau=5)\n",
    "        self.assertArrayEquals(actual, expected)\n",
    "               \n",
    "    def test_cost_function_should_compute_correct_cost_unweighted(self):\n",
    "        weights = np.ones(self.X.shape[0])\n",
    "        expected = 71.901\n",
    "        actual = cost_function(self.theta, self.X, self.y, weights)\n",
    "        self.assertFloatEquals(actual, expected) \n",
    "\n",
    "    def test_cost_function_should_compute_correct_cost_weighted(self):\n",
    "        weights = np.array([0.5, 0.1, 0.28])\n",
    "        expected = 18.860\n",
    "        actual = cost_function(self.theta, self.X, self.y, weights)\n",
    "        self.assertFloatEquals(actual, expected)\n",
    "\n",
    "    def test_cost_gradient_should_return_properly_shaped_vector(self):\n",
    "        weights = np.ones(self.X.shape[0])\n",
    "        grad = cost_function_gradient(self.theta, self.X, self.y, weights)\n",
    "        self.assertTrue(grad.shape == self.theta.shape)\n",
    "        \n",
    "    def test_cost_gradient_should_compute_correct_gradient_unweighted(self):\n",
    "        weights = np.ones(self.X.shape[0])\n",
    "        expected = [-12.373, -33.743, -9.036, -25.683]\n",
    "        actual = cost_function_gradient(self.theta, self.X, self.y, weights)\n",
    "        self.assertTrue(np.all(np.abs(actual - expected) < 1e-2))\n",
    "    \n",
    "    def test_cost_gradient_should_compute_correct_gradient_weighted(self):\n",
    "        weights = np.array([0.5, 0.1, 0.28])\n",
    "        expected = [-2.637, -2.674, -5.103, -3.968]\n",
    "        actual = cost_function_gradient(self.theta, self.X, self.y, weights)\n",
    "        self.assertTrue(np.all(np.abs(actual - expected) < 1e-2))\n",
    "        \n",
    "    def test_update_model_weights_should_not_update_when_gradient_is_zero(self):\n",
    "        grad = np.zeros(self.theta.shape[0])\n",
    "        theta_new = update_model_weights(self.theta, learning_rate=1, cost_gradient=grad)\n",
    "        self.assertArrayEquals(theta_new, self.theta)\n",
    "    \n",
    "    def test_update_model_weights_should_update_with_complete_gradient_if_learning_rate_is_one(self):\n",
    "        grad = np.array([1.35, -0.89, 0.16, 0.98])\n",
    "        expected = [0.65, 5.89, 6.84, 8.02]\n",
    "        actual = update_model_weights(self.theta, learning_rate=1, cost_gradient=grad)\n",
    "        self.assertArrayEquals(actual, expected)\n",
    "    \n",
    "    def test_update_model_weights_should_take_learning_rate_into_account(self):\n",
    "        grad = np.array([1.35, -0.89, 0.16, 0.98])\n",
    "        expected = [1.730, 5.178, 6.968, 8.804]\n",
    "        actual = update_model_weights(self.theta, learning_rate=0.2, cost_gradient=grad)\n",
    "        self.assertArrayEquals(actual, expected)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
